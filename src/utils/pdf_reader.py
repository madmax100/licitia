import os
import pytesseract
from PIL import Image
import fitz  # PyMuPDF
import tempfile
import re
from functools import lru_cache
import subprocess
import sys
import json
import shutil
from typing import List, Dict, Tuple
from pdf2image import convert_from_path
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_ollama import OllamaLLM

try:
    import pdfplumber
    PDFPLUMBER_AVAILABLE = True
except ImportError:
    PDFPLUMBER_AVAILABLE = False

def check_poppler_installation():
    """Verifica se o Poppler est√° instalado e no PATH."""
    try:
        # Tenta executar o comando pdfinfo
        result = subprocess.run(['pdfinfo'], 
                              stdout=subprocess.PIPE, 
                              stderr=subprocess.PIPE,
                              text=True,
                              timeout=2)
        
        # Se o comando retornar algo (mesmo que seja erro), significa que o pdfinfo existe
        return True
    except (subprocess.SubprocessError, FileNotFoundError, subprocess.TimeoutExpired):
        # Verifica se o Poppler est√° em locais comuns no Windows
        common_paths = [
            # Adicione o caminho personalizado como primeira op√ß√£o
            r"C:\Users\Cirilo\Downloads\Release-24.08.0-0\poppler-24.08.0\Library\bin",
            r"C:\Program Files\poppler\bin",
            r"C:\Program Files (x86)\poppler\bin",
            r"C:\poppler\bin",
            os.path.join(os.environ.get('LOCALAPPDATA', ''), 'poppler', 'bin')
        ]
        
        for path in common_paths:
            if os.path.exists(path) and os.path.exists(os.path.join(path, 'pdfinfo.exe')):
                # Adiciona o caminho ao PATH do processo atual
                print(f"üîç Poppler encontrado em: {path}")
                os.environ['PATH'] = path + os.pathsep + os.environ['PATH']
                return True
        
        return False

class PDFReader:
    def __init__(self, pdf_path, tesseract_path=None, use_ocr=True, max_pages_per_doc=20, model_name="phi4"):
        """
        Initialize the PDF reader.
        
        Args:
            pdf_path (str): Path to the PDF file
            tesseract_path (str, optional): Path to Tesseract executable
        """
        self.pdf_path = pdf_path
        if tesseract_path:
            pytesseract.pytesseract.tesseract_cmd = tesseract_path
        
        # Verifica se o Poppler est√° instalado
        if use_ocr:
            if not check_poppler_installation():
                print("\nAVISO: Poppler n√£o encontrado. O OCR ser√° desativado.")
                print("Para instalar o Poppler no Windows:")
                print("1. Baixe o Poppler do site: https://github.com/oschwartz10612/poppler-windows/releases/")
                print("2. Extraia o arquivo ZIP")
                print("3. Copie a pasta 'bin' para C:\\Program Files\\poppler\\bin")
                print("4. Adicione C:\\Program Files\\poppler\\bin ao PATH do sistema")
                print("5. Reinicie o computador")
                self.use_ocr = False
            else:
                print("Poppler encontrado com sucesso! OCR ativado.")
        
        # Template para extrair informa√ß√µes do documento
        self.prompt_template = PromptTemplate(
            input_variables=["text"],
            template="""
            Analise o seguinte texto e extraia as seguintes informa√ß√µes:
            1. T√≠tulo do documento
            2. Data de assinatura (se houver)
            
            Texto: {text}
            
            Responda no formato JSON:
            {{
                "titulo": "t√≠tulo do documento",
                "data_assinatura": "data de assinatura (se encontrada)"
            }}
            """
        )
        
        self.llm = OllamaLLM(model=model_name)
        self.use_ocr = use_ocr
        self.max_pages_per_doc = max_pages_per_doc

    def _get_total_pages(self, pdf_path: str) -> int:
        """Retorna o n√∫mero total de p√°ginas do PDF."""
        with pdfplumber.open(pdf_path) as pdf:
            return len(pdf.pages)

    def _split_pdf(self, pdf_path: str) -> List[str]:
        """Divide o PDF em arquivos menores se necess√°rio."""
        total_pages = self._get_total_pages(pdf_path)
        if total_pages <= self.max_pages_per_doc:
            return [pdf_path]
        
        # Cria diret√≥rio tempor√°rio para os PDFs divididos
        temp_dir = tempfile.mkdtemp()
        pdf_files = []
        
        with pdfplumber.open(pdf_path) as pdf:
            for i in range(0, total_pages, self.max_pages_per_doc):
                end_page = min(i + self.max_pages_per_doc, total_pages)
                output_path = os.path.join(temp_dir, f'parte_{i//self.max_pages_per_doc + 1}.pdf')
                
                # Cria um novo PDF com as p√°ginas do intervalo
                with pdfplumber.open(pdf_path) as source:
                    pages = source.pages[i:end_page]
                    with pdfplumber.open(output_path, 'wb') as dest:
                        for page in pages:
                            dest.add_page(page)
                
                pdf_files.append(output_path)
        
        return pdf_files

    def _extract_text_with_ocr(self, pdf_path: str) -> List[str]:
        """Extrai texto de cada p√°gina do PDF usando OCR."""
        if not check_poppler_installation():
            raise RuntimeError("Poppler n√£o est√° instalado. Por favor, instale o Poppler para usar OCR.")
            
        textos = []
        with tempfile.TemporaryDirectory() as temp_dir:
            try:
                # Converte PDF para imagens
                images = convert_from_path(pdf_path)
                
                for i, image in enumerate(images):
                    # Salva a imagem temporariamente
                    temp_image_path = os.path.join(temp_dir, f'page_{i}.png')
                    image.save(temp_image_path, 'PNG')
                    
                    # Aplica OCR na imagem
                    texto = pytesseract.image_to_string(Image.open(temp_image_path), lang='por')
                    textos.append(texto)
            except Exception as e:
                print(f"Erro durante a convers√£o do PDF: {e}")
                raise RuntimeError("Erro ao converter PDF para imagens. Verifique se o Poppler est√° instalado corretamente.")
        
        return textos

    def _show_cursor_variables(self, current_doc: Dict, i: int, total_pages: int):
        """Mostra as vari√°veis armazenadas no cursor."""
        print("\nVari√°veis do cursor:")
        print(f"P√°gina atual: {i}/{total_pages}")
        print(f"P√°gina de in√≠cio do documento atual: {current_doc.get('pagina_inicio', 'N/A')}")
        print(f"P√°gina de fim do documento atual: {current_doc.get('pagina_fim', 'N/A')}")
        print(f"Tamanho do texto atual: {len(current_doc.get('texto', ''))} caracteres")
        print(f"Primeiros 100 caracteres do texto: {current_doc.get('texto', '')[:100]}...")
        print("-" * 50)

   
        """Salva as vari√°veis do cursor em um arquivo JSON."""
        log_file = "cursor_variables.json"
        
        # Cria o dicion√°rio com as vari√°veis
        cursor_data = {
            "pagina_atual": i,
            "total_paginas": total_pages,
            "documento_atual": {
                "pagina_inicio": current_doc.get('pagina_inicio', 'N/A'),
                "pagina_fim": current_doc.get('pagina_fim', 'N/A'),
                "tamanho_texto": len(current_doc.get('texto', '')),
                "primeiros_100_caracteres": current_doc.get('texto', '')[:100]
            }
        }
        
        # Se o arquivo j√° existe, carrega os dados existentes
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                try:
                    existing_data = json.load(f)
                except json.JSONDecodeError:
                    existing_data = {"registros": []}
        else:
            existing_data = {"registros": []}
        
        # Adiciona o novo registro
        existing_data["registros"].append(cursor_data)
        
        # Salva os dados atualizados
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=4)

    def process_pdf(self, pdf_path: str) -> Tuple[List[Dict], int]:
        """Processa o PDF e retorna informa√ß√µes sobre cada documento e o total de p√°ginas."""
        total_pages = self._get_total_pages(pdf_path)
        pdf_files = self._split_pdf(pdf_path)
        all_documentos = []
        
        # Limpa o arquivo de log se ele existir
        if os.path.exists("cursor_variables.json"):
            os.remove("cursor_variables.json")
        
        for pdf_file in pdf_files:
            documentos = []
            
            if self.use_ocr:
                try:
                    # Extrai texto usando OCR
                    textos = self._extract_text_with_ocr(pdf_file)
                except RuntimeError as e:
                    print(f"Erro ao usar OCR: {e}")
                    print("Continuando com extra√ß√£o de texto normal...")
                    self.use_ocr = False
                    textos = []
                    with pdfplumber.open(pdf_file) as pdf:
                        for page in pdf.pages:
                            texto = page.extract_text()
                            textos.append(texto if texto else "")
            else:
                # Extrai texto diretamente do PDF
                textos = []
                with pdfplumber.open(pdf_file) as pdf:
                    for page in pdf.pages:
                        texto = page.extract_text()
                        textos.append(texto if texto else "")
            
            current_doc = {
                "pagina_inicio": 1,
                "texto": ""
            }
            
            for i, texto in enumerate(textos, 1):
                print(f"\rAnalisando p√°gina {i} de {total_pages}...", end="")
                if not texto.strip():
                    continue
                
                # Salva as vari√°veis do cursor a cada 10 p√°ginas
                if i % 10 == 0:
                    self._save_cursor_variables(current_doc, i, total_pages)
                
                # Verifica se h√° uma quebra clara de documento
                if self._is_document_break(texto):
                    if current_doc["texto"]:
                        # Processa o documento atual
                        print(f"\nIdentificado novo documento na p√°gina {i}")
                        info = self._process_document(current_doc)
                        documentos.append(info)
                    
                    # Inicia novo documento
                    current_doc = {
                        "pagina_inicio": i,
                        "texto": texto
                    }
                else:
                    current_doc["texto"] += "\n" + texto
                    current_doc["pagina_fim"] = i
            
            # Processa o √∫ltimo documento
            if current_doc["texto"]:
                info = self._process_document(current_doc)
                documentos.append(info)
            
            all_documentos.extend(documentos)
        
        print("\nAn√°lise conclu√≠da!")
        print(f"Vari√°veis do cursor salvas em cursor_variables.json")
        return all_documentos, total_pages

    def _is_document_break(self, texto: str) -> bool:
        """Verifica se h√° uma quebra clara de documento."""
        # Texto muito curto geralmente indica uma quebra (p√°gina de separa√ß√£o ou in√≠cio de documento)
        if len(texto.strip()) < 150 and len(texto.strip()) > 10:
            # Pequenos textos isolados frequentemente s√£o separadores ou p√°ginas de t√≠tulo
            return True
            
        # Verifica se o texto come√ßa com numera√ß√£o (comum em novos documentos)
        if re.match(r'^\s*\d+[\.-]\s+', texto[:50]):
            return True
            
        # Verifica se h√° cabe√ßalhos comuns que indicam novos documentos
        cabecalhos = ['of√≠cio', 'memorando', 'relat√≥rio', 'carta', 'despacho', 'certid√£o', 
                      'parecer', 'anexo', 'termo', 'formul√°rio', 'requerimento', 'documento',
                      'comprovante', 'declara√ß√£o', 'notifica√ß√£o', 'intima√ß√£o', 'informa√ß√£o',
                      'pedido', 'solicita√ß√£o', 'presta√ß√£o', 'aviso', 'comunicado']
                      
        for cabecalho in cabecalhos:
            if re.search(fr'^\s*{cabecalho}\b', texto[:100], re.IGNORECASE):
                return True
        
        # Verifica se come√ßa com data (comum em novos documentos)
        if re.search(r'^\s*\d{1,2}[/.-]\d{1,2}[/.-]\d{2,4}', texto[:50]):
            return True
            
        # Verifica por n√∫meros de processo, protocolos, etc.
        if re.search(r'\b(processo|sei|protocolo|registro)[\s\.:].*?\d+', texto[:200], re.IGNORECASE):
            return True
            
        # Verifica n√∫meros de documentos
        if re.search(r'\b(n[¬∫¬∞\.]*|n√∫mero)[\s:]*\d+[/.-]?\d*', texto[:200], re.IGNORECASE):
            return True
            
        # Verifica por assinaturas no final da p√°gina anterior
        if re.search(r'(atenciosamente|respeitosamente|cordialmente)\s*[,\.]\s*$', texto, re.IGNORECASE):
            return True
            
        # Padr√µes que podem indicar in√≠cio de novo documento
        padroes = [
            r"^\s*DOCUMENTO\s*",
            r"^\s*CONTRATO\s*",
            r"^\s*TERMO\s*DE\s*",
            r"^\s*ATA\s*DE\s*",
            r"^\s*PROCESSO\s*",
            r"^\s*PETI√á√ÉO\s*",
            r"^\s*SENTEN√áA",
            r"^\s*DECIS√ÉO",
            r"^\s*DESPACHO",
            r"^\s*CERTID√ÉO",
            r"^\s*REQUERIMENTO",
            r"^\s*OF√çCIO",
            r"^\s*NOTIFICA√á√ÉO",
            r"^\s*INTIMA√á√ÉO",
            r"^\s*CITA√á√ÉO",
            r"^\s*MANDADO",
            r"^\s*EDITAL",
            r"^\s*LAUDO",
            r"^\s*PER√çCIA",
            r"^\s*INQU√âRITO",
            r"^\s*MINIST√âRIO\s*",
            r"^\s*DEPARTAMENTO\s*",
            r"^\s*SECRETARIA\s*",
            r"^\s*DELEGACIA\s*",
            r"^\s*PLANILHA\s*"
        ]
        
        # Verifica se o texto come√ßa com algum dos padr√µes
        for padrao in padroes:
            if re.search(padrao, texto[:200], re.IGNORECASE):
                return True
                
        # Verifica por cabe√ßalhos/logos no topo da p√°gina
        if re.search(r'^[\s\*=-]{0,10}[A-Z√á√Å√â√ç√ì√ö√Ç√ä√é√î√õ√É√ï\s]{10,}[\s\*=-]{0,10}$', texto[:200], re.MULTILINE):
            return True
        
        # Verifica por uma mudan√ßa significativa no conte√∫do
        palavras_chave = ["processo", "peti√ß√£o", "senten√ßa", "decis√£o", "despacho",
                          "certid√£o", "requerimento", "of√≠cio", "notifica√ß√£o", "intima√ß√£o",
                          "cita√ß√£o", "mandado", "edital", "laudo", "per√≠cia", "inqu√©rito",
                          "planilha", "or√ßament√°ria", "projeto", "b√°sico", "licita√ß√£o",
                          "proposta", "contrato", "parecer", "ata", "memorial", "cronograma",
                          "termo", "relat√≥rio", "requisi√ß√£o", "empenho", "comprovante"]
        
        # Conta a ocorr√™ncia de palavras-chave no texto - precisa de pelo menos 2
        contagem = sum(1 for palavra in palavras_chave if palavra.lower() in texto.lower())
        return contagem >= 2

    def _process_document(self, doc: Dict) -> Dict:
        """Processa um documento individual usando o modelo de IA."""
        try:
            # Template mais detalhado para extrair informa√ß√µes
            prompt_template = PromptTemplate(
                input_variables=["text"],
                template="""
                Analise o seguinte texto e extraia as seguintes informa√ß√µes:
                1. T√≠tulo do documento (se houver)
                2. Descri√ß√£o do documento (resumo do conte√∫do)
                3. Data do documento (se houver)
                4. Tipo de documento (contrato, edital, parecer, etc)
                5. N√∫mero do documento (se houver)
                6. Valor (se mencionado)
                7. Objeto (se mencionado)
                
                Texto: {text}
                
                Responda no formato JSON:
                {{
                    "titulo": "t√≠tulo do documento",
                    "descricao": "descri√ß√£o do documento",
                    "data": "data do documento",
                    "tipo": "tipo do documento",
                    "numero": "n√∫mero do documento",
                    "valor": "valor mencionado",
                    "objeto": "objeto do documento"
                }}
                """
            )
            
            chain = LLMChain(llm=self.llm, prompt=prompt_template)
            resultado = chain.invoke({"text": doc["texto"]})
            info = json.loads(resultado["text"])
            
            # Adiciona informa√ß√µes de pagina√ß√£o
            info.update({
                "pagina_inicio": doc["pagina_inicio"],
                "pagina_fim": doc.get("pagina_fim", doc["pagina_inicio"])
            })
            
            return info
        except Exception as e:
            print(f"Erro ao processar documento: {e}")
            return {
                "titulo": "Documento n√£o identificado",
                "descricao": "N√£o foi poss√≠vel extrair informa√ß√µes",
                "data": "N√£o encontrada",
                "tipo": "N√£o identificado",
                "numero": "N√£o encontrado",
                "valor": "N√£o encontrado",
                "objeto": "N√£o encontrado",
                "pagina_inicio": doc["pagina_inicio"],
                "pagina_fim": doc.get("pagina_fim", doc["pagina_inicio"])
            }
    
    def extract_text(self, use_ocr=False):
        """
        Extract text from a PDF file using PyMuPDF with fallback to pdfplumber.
        
        Args:
            use_ocr (bool): Whether to use OCR for text extraction
            
        Returns:
            list: List of strings containing text for each page
        """
        if not os.path.exists(self.pdf_path):
            raise FileNotFoundError(f"PDF file not found: {self.pdf_path}")
        
        # Tenta primeiro com pdfplumber (que sabemos que est√° sendo importado)
        try:
            pages_content = []
            with pdfplumber.open(self.pdf_path) as pdf:
                for page in pdf.pages:
                    text = page.extract_text(x_tolerance=3, y_tolerance=3)
                    pages_content.append(text if text else "")
                    
            print(f"‚úÖ Texto extra√≠do com pdfplumber: {len(pages_content)} p√°ginas")
            return pages_content
                    
        except Exception as e:
            print(f"‚ö†Ô∏è Error with pdfplumber: {e}. Tentando com OCR...")
            
            # Fallback para OCR se pdfplumber falhar
            if use_ocr:
                try:
                    print("üîç Iniciando extra√ß√£o com OCR...")
                    images = convert_from_path(self.pdf_path)
                    
                    pages_content = []
                    for i, image in enumerate(images):
                        # Aplica OCR na imagem
                        text = pytesseract.image_to_string(image, lang='por')
                        pages_content.append(text)
                        
                    print(f"‚úÖ Texto extra√≠do com OCR: {len(pages_content)} p√°ginas")
                    return pages_content
                    
                except Exception as e2:
                    raise Exception(f"Failed to extract text with both pdfplumber and OCR: {e}, {e2}")
                
            else:
                raise Exception(f"pdfplumber failed and no valid text was extracted: {e}")

    def identify_document_boundaries(self, pages_content, ai_processor=None):
        """
        Identifica os limites de cada documento no PDF usando o modelo de IA,
        j√° extraindo resumo, data e valores de cada p√°gina.
        """
        print("üîç Identificando limites de documentos no PDF (usando IA p√°gina por p√°gina)...")

        documents = []
        current_doc_pages = []
        current_doc_start = 0
        current_doc_resumos = []
        current_doc_datas = []
        current_doc_valores = []

        # Prompt para o modelo decidir se √© in√≠cio de novo documento e extrair informa√ß√µes
        boundary_prompt = PromptTemplate(
            input_variables=["text"],
            template=(
                "O texto a seguir foi extra√≠do de uma p√°gina de um PDF.\n"
                "1. Responda apenas com 'SIM' se esta p√°gina √© o IN√çCIO de um novo documento, ou 'N√ÉO' caso contr√°rio.\n"
                "2. Extraia um resumo curto do conte√∫do da p√°gina.\n"
                "3. Se houver, extraia a data principal e valores monet√°rios.\n"
                "Responda no formato JSON:\n"
                "{\n"
                "  \"novo_documento\": \"SIM\" ou \"N√ÉO\",\n"
                "  \"resumo\": \"...\",\n"
                "  \"data\": \"...\",\n"
                "  \"valores\": [ ... ]\n"
                "}\n"
                "Texto:\n{text}\n"
                "Resposta:"
            )
        )
        chain = boundary_prompt | self.llm

        for i, page_content in enumerate(pages_content):
            is_new_doc = False
            page_number = i + 1
            resumo = ""
            data = ""
            valores = []

            # Sempre novo documento na primeira p√°gina
            if i == 0:
                is_new_doc = True
                print(f"  üìÑ P√°gina {page_number}: In√≠cio do primeiro documento")
            else:
                # Usa o modelo para decidir e extrair informa√ß√µes
                try:
                    resposta = chain.invoke({"text": page_content})
                    info = json.loads(resposta)
                    is_new_doc = info.get("novo_documento", "").strip().upper().startswith("SIM")
                    resumo = info.get("resumo", "")
                    data = info.get("data")
                    valores = info.get("valores", [])
                except Exception as e:
                    print(f"‚ö†Ô∏è Erro ao consultar IA ou interpretar resposta na p√°gina {page_number}: {e}")
                    # fallback simples
                    is_new_doc = self._is_document_break(page_content)
                    resumo = ""
                    data = ""
                    valores = []

            # Se for novo documento e j√° temos p√°ginas acumuladas, finalize o anterior
            if is_new_doc and current_doc_pages:
                doc_end = i
                documents.append({
                    "start_page": current_doc_start + 1,
                    "end_page": doc_end,
                    "pages_content": current_doc_pages,
                    "resumos": current_doc_resumos,
                    "datas": current_doc_datas,
                    "valores": current_doc_valores
                })
                print(f"  ‚úÖ Documento finalizado: p√°ginas {current_doc_start+1}-{doc_end}")
                # Inicia novo documento
                current_doc_pages = [page_content]
                current_doc_start = i
                current_doc_resumos = [resumo]
                current_doc_datas = [data]
                current_doc_valores = [valores]
            else:
                current_doc_pages.append(page_content)
                current_doc_resumos.append(resumo)
                current_doc_datas.append(data)
                current_doc_valores.append(valores)

        # Adiciona o √∫ltimo documento
        if current_doc_pages:
            documents.append({
                "start_page": current_doc_start + 1,
                "end_page": len(pages_content),
                "pages_content": current_doc_pages,
                "resumos": current_doc_resumos,
                "datas": current_doc_datas,
                "valores": current_doc_valores
            })
            print(f"  ‚úÖ Documento final: p√°ginas {current_doc_start+1}-{len(pages_content)}")

        print(f"üìë Identificados {len(documents)} documentos no PDF")
        return documents

    # Adicione esta fun√ß√£o auxiliar para calcular similaridade de texto
    def _text_similarity(self, text1, text2):
        """Calcula a similaridade entre dois textos (medida simples)"""
        if not text1 or not text2:
            return 0
            
        # Remove espa√ßos e pontua√ß√£o para compara√ß√£o
        t1 = re.sub(r'[^\w\s]', '', text1.lower())
        t2 = re.sub(r'[^\w\s]', '', text2.lower())
        
        # Divide em palavras
        words1 = set(t1.split())
        words2 = set(t2.split())
        
        # Calcula interse√ß√£o
        common = words1.intersection(words2)
        
        # Calcula coeficiente de Jaccard
        if len(words1) == 0 and len(words2) == 0:
            return 1.0
        elif len(words1) == 0 or len(words2) == 0:
            return 0.0
        else:
            return len(common) / (len(words1) + len(words2) - len(common))